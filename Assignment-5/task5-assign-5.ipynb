{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f8a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores (gender-ignored):\n",
      "  female: 47.42\n",
      "  male: 34.0\n",
      "  non_binary: 58.0\n",
      "Counterfactual gender check: {'total_comparisons': 15, 'changed_count': 0, 'fraction_changed': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# inclusive_scoring.py\n",
    "from typing import Dict, List, Tuple\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- Canonicalize gender labels (for logging/audit only) ---\n",
    "def normalize_gender(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize common gender strings into canonical categories used for auditing only.\n",
    "    Returns one of: 'male', 'female', 'non_binary', 'other', 'unknown'\n",
    "    This function is not used in scoring; it's only for consistent logging/audit.\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return 'unknown'\n",
    "    v = value.strip().lower()\n",
    "    if v in {'m', 'male', 'man'}:\n",
    "        return 'male'\n",
    "    if v in {'f', 'female', 'woman'}:\n",
    "        return 'female'\n",
    "    if v in {'nb', 'non-binary', 'nonbinary', 'non binary', 'nonbinary', 'enby'}:\n",
    "        return 'non_binary'\n",
    "    if v in {'other', 'prefer not to say', 'prefer-not-to-say'}:\n",
    "        return 'other'\n",
    "    return 'unknown'\n",
    "\n",
    "# --- Inclusive scoring (GENDER-IGNORANT) ---\n",
    "def score_applicant_inclusive(applicant: Dict[str, float],\n",
    "                              weights: Dict[str, float] = None) -> float:\n",
    "    \"\"\"\n",
    "    Compute an inclusive applicant score WITHOUT using gender or other protected attributes.\n",
    "    Inputs:\n",
    "      applicant: dict with numeric keys:\n",
    "        - education_years (float)\n",
    "        - years_experience (float)\n",
    "        - skill_score (float) 0-100\n",
    "        - certifications_count (float)\n",
    "      weights: optional dict for feature weights (edu, exp, skill, cert)\n",
    "    Returns:\n",
    "      score (float) in range [0.0, 100.0]\n",
    "    \"\"\"\n",
    "    # Default weights (sum to 1.0)\n",
    "    if weights is None:\n",
    "        weights = {'edu': 0.2, 'exp': 0.3, 'skill': 0.4, 'cert': 0.1}\n",
    "    # Extract features with safe defaults\n",
    "    edu = float(applicant.get('education_years', 0.0))\n",
    "    exp = float(applicant.get('years_experience', 0.0))\n",
    "    skill = float(applicant.get('skill_score', 0.0))\n",
    "    certs = float(applicant.get('certifications_count', 0.0))\n",
    "\n",
    "    # Feature normalization (safe, clamped ranges)\n",
    "    edu_norm = min(max(edu, 0.0), 30.0) / 30.0        # 0-30 years map -> 0-1\n",
    "    exp_norm = min(max(exp, 0.0), 40.0) / 40.0        # 0-40 years -> 0-1\n",
    "    skill_norm = min(max(skill, 0.0), 100.0) / 100.0  # 0-100 -> 0-1\n",
    "    cert_norm = min(max(certs, 0.0), 20.0) / 20.0     # 0-20 -> 0-1\n",
    "\n",
    "    raw = (weights['edu'] * edu_norm +\n",
    "           weights['exp'] * exp_norm +\n",
    "           weights['skill'] * skill_norm +\n",
    "           weights['cert'] * cert_norm)\n",
    "\n",
    "    score = round(raw * 100.0, 2)\n",
    "    return score\n",
    "\n",
    "# --- Counterfactual invariance check across gender categories ---\n",
    "def counterfactual_gender_check(applicants: List[Dict],\n",
    "                                score_fn,\n",
    "                                sensitive_key: str = 'gender',\n",
    "                                canonical_values: List[str] = None,\n",
    "                                allowed_diff: float = 1e-8) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    For each applicant, create counterfactual copies with different canonical gender values and\n",
    "    verify scores do not change. Returns summary statistics: fraction_changed.\n",
    "    canonical_values: list of canonical genders to test (e.g., ['male','female','non_binary','other'])\n",
    "    \"\"\"\n",
    "    if canonical_values is None:\n",
    "        canonical_values = ['male', 'female', 'non_binary', 'other', 'unknown']\n",
    "\n",
    "    total = 0\n",
    "    changed = 0\n",
    "    for a in applicants:\n",
    "        # compute original score (without modifying input)\n",
    "        s_orig = score_fn(a)\n",
    "        for g in canonical_values:\n",
    "            a_copy = deepcopy(a)\n",
    "            # Only modify the sensitive_key for counterfactual test\n",
    "            a_copy[sensitive_key] = g\n",
    "            s_cf = score_fn(a_copy)\n",
    "            total += 1\n",
    "            if abs(s_orig - s_cf) > allowed_diff:\n",
    "                changed += 1\n",
    "    return {'total_comparisons': total, 'changed_count': changed, 'fraction_changed': changed / total if total else 0.0}\n",
    "\n",
    "# --- Example unit test helpers ---\n",
    "def test_counterfactual_invariance_single():\n",
    "    base = {'education_years': 16, 'years_experience': 5, 'skill_score': 80.0, 'certifications_count': 2, 'gender': 'female'}\n",
    "    copy = base.copy()\n",
    "    copy['gender'] = 'male'\n",
    "    assert score_applicant_inclusive(base) == score_applicant_inclusive(copy), \"Inclusive scorer must be invariant to gender\"\n",
    "\n",
    "def run_quick_demo():\n",
    "    # Demonstrative synthetic batch\n",
    "    applicants = [\n",
    "        {'education_years': 16, 'years_experience': 5, 'skill_score': 80.0, 'certifications_count': 2, 'gender': 'female'},\n",
    "        {'education_years': 12, 'years_experience': 2, 'skill_score': 60.0, 'certifications_count': 1, 'gender': 'male'},\n",
    "        {'education_years': 18, 'years_experience': 10, 'skill_score': 90.0, 'certifications_count': 5, 'gender': 'non-binary'},\n",
    "    ]\n",
    "    print(\"Scores (gender-ignored):\")\n",
    "    for a in applicants:\n",
    "        print(f\"  {normalize_gender(a.get('gender'))}: {score_applicant_inclusive(a)}\")\n",
    "    print(\"Counterfactual gender check:\", counterfactual_gender_check(applicants, score_applicant_inclusive))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_quick_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
